{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Q Network for navigating through a grid world with different goal locations\n",
    "#### Reward system: Negative of euclidean distance to goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-21 16:21:13.499690: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-21 16:21:14.223271: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-07-21 16:21:16.008757: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-21 16:21:16.025271: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-21 16:21:16.025434: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-21 16:21:16.026156: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-21 16:21:16.026393: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-21 16:21:16.026607: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-21 16:21:16.074542: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-21 16:21:16.074697: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-21 16:21:16.074808: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-21 16:21:16.074937: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2278 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "now = time.localtime()\n",
    "subdir = time.strftime(\"%d-%b-%Y_%H.%M.%S\", now)\n",
    "\n",
    "summary_dir1 = os.path.join(\"stackoverflow\", subdir, \"t1\")\n",
    "summary_writer1 = tf.summary.create_file_writer(summary_dir1)\n",
    "\n",
    "for cont in range(200):\n",
    "    with summary_writer1.as_default():\n",
    "        tf.summary.scalar(name=\"unify/sin_x\", data=np.math.sin(cont) ,step=cont)\n",
    "        tf.summary.scalar(name=\"unify/sin_x_2\", data=np.math.sin(cont/2), step=cont)\n",
    "    summary_writer1.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from collections import deque\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/pradeep/miniconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n"
     ]
    }
   ],
   "source": [
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# print gpu info\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a neural network model\n",
    "def create_model(input_shape, num_actions):\n",
    "    model = Sequential([\n",
    "        Input(shape=input_shape),\n",
    "        Dense(16, activation='relu'),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(num_actions, activation='linear')\n",
    "    ])\n",
    "    model.compile(loss='mse', optimizer=Adam(learning_rate=0.01))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a class for the environment\n",
    "class Env():\n",
    "    def __init__(self, grid_size=6, max_steps=100):\n",
    "        self.grid_size = grid_size\n",
    "        self.max_steps = max_steps\n",
    "        self.goal = np.random.randint(0, grid_size, size=2) # random goal\n",
    "        print('Goal:', self.goal)\n",
    "\n",
    "        self.rewards = np.zeros((grid_size, grid_size))\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.pos = np.random.randint(0, self.grid_size, size=2)\n",
    "        self.steps = 0\n",
    "        self.done = False\n",
    "        return self.pos\n",
    "    \n",
    "    def reset_goal(self):\n",
    "        self.goal = np.random.randint(0, self.grid_size, size=2)\n",
    "        print('Goal:', self.goal)\n",
    "        for i in range(self.grid_size):\n",
    "            for j in range(self.grid_size):\n",
    "                self.rewards[i, j] = -self.euclidean_distance_from_goal(np.array([i, j]))\n",
    "        self.rewards[self.goal[0], self.goal[1]] = 100\n",
    "        return self.goal\n",
    "    \n",
    "    def step(self, action):\n",
    "        self.steps += 1\n",
    "        if action == 0 and self.pos[0] < self.grid_size - 1: # right\n",
    "            self.pos[0] += 1\n",
    "        elif action == 1 and self.pos[0] > 0: # left\n",
    "            self.pos[0] -= 1\n",
    "        elif action == 2 and self.pos[1] > 0: # down\n",
    "            self.pos[1] -= 1\n",
    "        elif action == 3 and self.pos[1] < self.grid_size - 1: # up\n",
    "            self.pos[1] += 1\n",
    "        else:\n",
    "            pass\n",
    "            # raise ValueError('Invalid action')\n",
    "        if np.array_equal(self.pos, self.goal):\n",
    "            self.done = True\n",
    "            reward = 0\n",
    "            # reward = 100\n",
    "        elif self.steps >= self.max_steps:\n",
    "            self.done = True\n",
    "            reward = self.rewards[self.pos[0], self.pos[1]]\n",
    "        else:\n",
    "            reward = self.rewards[self.pos[0], self.pos[1]]\n",
    "        return self.pos, reward, self.done\n",
    "\n",
    "    def euclidean_distance_from_goal(self, pos):\n",
    "        dist = np.sqrt(np.sum((pos - self.goal) ** 2))\n",
    "        return dist\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an agent class\n",
    "class Agent():\n",
    "    def __init__(self, env, model, target_model):\n",
    "        self.env = env\n",
    "        self.model = model\n",
    "        self.target_model = target_model\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "        self.gamma = 0.7\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.005\n",
    "        self.batch_size = 64\n",
    "        self.memory = deque(maxlen=10000)\n",
    "        \n",
    "\n",
    "    def add_to_memory(self, state, goal, action, reward, next_state, done):\n",
    "        self.memory.append((state, goal, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            return np.random.randint(0, 4)\n",
    "        else:\n",
    "            # Pre-process the input\n",
    "            inputt = np.concatenate((state, self.env.goal))\n",
    "            inputt = tf.convert_to_tensor(inputt)\n",
    "            inputt = tf.expand_dims(inputt, 0)\n",
    "\n",
    "            return np.argmax(self.model.predict(inputt, verbose=0)[0]) # TODO: check the predict output\n",
    "\n",
    "    def predict(self, inputt):\n",
    "\n",
    "        return np.argmax(self.model.predict(inputt, verbose=0)[0])\n",
    "\n",
    "    def replay(self):\n",
    "        batch = random.sample(self.memory, self.batch_size)\n",
    "        for state, goal, action, reward, next_state, done in batch:\n",
    "            \n",
    "            target = reward\n",
    "\n",
    "            if not done:\n",
    "                # Pre-process the next state input\n",
    "                input_next = np.concatenate((next_state, goal))\n",
    "                input_next = tf.convert_to_tensor(input_next)\n",
    "                input_next = tf.expand_dims(input_next, 0)\n",
    "\n",
    "                target += self.gamma * np.amax(self.target_model.predict(input_next, verbose=0)[0])\n",
    "\n",
    "            # Pre-process the current state input\n",
    "            inputt = np.concatenate((state, goal))\n",
    "            inputt = tf.convert_to_tensor(inputt)\n",
    "            inputt = tf.expand_dims(inputt, 0)\n",
    "\n",
    "            cur_q_value = self.model.predict(inputt, verbose=0) # Q-value of current state\n",
    "            cur_q_value[0][action] = target # TODO: check the predict output\n",
    "            \n",
    "            self.model.fit(inputt, cur_q_value, epochs=1, verbose=0)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new model\n",
      "Goal: [4 5]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the agent\n",
    "\n",
    "try:\n",
    "    model = tf.keras.models.load_model('doublenet_dqn_diff_start_diff_goal.h5')\n",
    "    print(\"Loaded model from disk\")\n",
    "    agent = Agent(Env(), model=model, target_model=model)\n",
    "except:\n",
    "    print(\"Creating new model\")\n",
    "    agent = Agent(Env(), model=create_model(input_shape=(4,), num_actions=4), target_model=create_model(input_shape=(4,), num_actions=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goal: [3 4]\n",
      "Episode: 0/250, steps: 47, e: 1.0\n",
      "State list: [array([2, 2]), array([3, 2]), array([3, 1]), array([3, 2]), array([3, 1]), array([3, 0]), array([3, 1]), array([2, 1]), array([2, 0]), array([2, 0]), array([2, 0]), array([2, 0]), array([2, 0]), array([2, 0]), array([1, 0]), array([1, 1]), array([1, 2]), array([1, 3]), array([0, 3]), array([0, 2]), array([0, 2]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 3]), array([1, 3]), array([2, 3]), array([2, 4]), array([2, 3]), array([3, 3]), array([3, 4]), array([3, 5]), array([2, 5]), array([3, 5]), array([3, 4]), array([3, 3]), array([3, 4]), array([3, 3]), array([4, 3]), array([5, 3]), array([5, 3]), array([4, 3]), array([4, 2]), array([4, 3]), array([5, 3]), array([5, 4]), array([4, 4])]\n",
      "Episode: 1/250, steps: 100, e: 1.0\n",
      "State list: [array([0, 0]), array([0, 1]), array([0, 0]), array([0, 0]), array([1, 0]), array([2, 0]), array([1, 0]), array([1, 1]), array([0, 1]), array([0, 2]), array([0, 1]), array([1, 1]), array([1, 0]), array([2, 0]), array([3, 0]), array([2, 0]), array([3, 0]), array([3, 0]), array([4, 0]), array([4, 1]), array([4, 0]), array([5, 0]), array([4, 0]), array([4, 0]), array([4, 0]), array([3, 0]), array([2, 0]), array([3, 0]), array([2, 0]), array([2, 1]), array([2, 2]), array([1, 2]), array([2, 2]), array([1, 2]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1]), array([0, 2]), array([1, 2]), array([0, 2]), array([0, 2]), array([0, 3]), array([1, 3]), array([1, 2]), array([0, 2]), array([0, 2]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 3]), array([1, 3]), array([1, 4]), array([1, 3]), array([1, 2]), array([1, 1]), array([1, 0]), array([0, 0]), array([0, 0]), array([0, 0]), array([0, 0]), array([1, 0]), array([2, 0]), array([1, 0]), array([0, 0]), array([1, 0]), array([1, 1]), array([1, 2]), array([1, 1]), array([0, 1]), array([1, 1]), array([0, 1]), array([0, 0]), array([0, 0]), array([0, 0]), array([0, 0]), array([1, 0]), array([1, 0]), array([2, 0]), array([1, 0]), array([1, 1]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 4]), array([0, 4]), array([0, 3]), array([0, 4]), array([0, 4])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-21 16:21:18.916403: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-07-21 16:21:19.511451: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x3ba7000 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-07-21 16:21:19.511487: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Laptop GPU, Compute Capability 8.6\n",
      "2023-07-21 16:21:19.514330: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-07-21 16:21:19.525569: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-07-21 16:21:19.570421: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2023-07-21 16:21:19.571876: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:231] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.6\n",
      "2023-07-21 16:21:19.571890: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:234] Used ptxas at ptxas\n",
      "2023-07-21 16:21:19.585544: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2023-07-21 16:21:19.634739: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2023-07-21 16:21:19.705562: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2023-07-21 16:21:19.773831: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2023-07-21 16:21:19.841571: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2023-07-21 16:21:19.905743: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goal: [3 1]\n",
      "Episode: 2/250, steps: 2, e: 1.0\n",
      "State list: [array([3, 2]), array([3, 3])]\n",
      "Goal: [2 5]\n",
      "Episode: 3/250, steps: 16, e: 0.99\n",
      "State list: [array([2, 2]), array([1, 2]), array([2, 2]), array([1, 2]), array([1, 3]), array([2, 3]), array([3, 3]), array([4, 3]), array([4, 2]), array([4, 3]), array([5, 3]), array([4, 3]), array([3, 3]), array([3, 2]), array([2, 2]), array([3, 2])]\n",
      "Episode: 4/250, steps: 100, e: 0.99\n",
      "State list: [array([4, 5]), array([4, 5]), array([3, 5]), array([3, 4]), array([3, 3]), array([3, 4]), array([2, 4]), array([2, 3]), array([3, 3]), array([4, 3]), array([3, 3]), array([2, 3]), array([2, 4]), array([3, 4]), array([4, 4]), array([5, 4]), array([5, 5]), array([5, 4]), array([5, 5]), array([4, 5]), array([4, 5]), array([4, 5]), array([4, 4]), array([4, 5]), array([5, 5]), array([5, 5]), array([4, 5]), array([4, 5]), array([3, 5]), array([4, 5]), array([4, 5]), array([4, 4]), array([5, 4]), array([5, 3]), array([5, 2]), array([4, 2]), array([4, 3]), array([5, 3]), array([5, 3]), array([5, 3]), array([4, 3]), array([3, 3]), array([4, 3]), array([5, 3]), array([4, 3]), array([4, 2]), array([4, 1]), array([5, 1]), array([4, 1]), array([4, 2]), array([4, 3]), array([3, 3]), array([2, 3]), array([3, 3]), array([3, 4]), array([4, 4]), array([4, 5]), array([4, 4]), array([4, 3]), array([4, 2]), array([3, 2]), array([3, 3]), array([4, 3]), array([5, 3]), array([4, 3]), array([4, 2]), array([4, 1]), array([5, 1]), array([5, 2]), array([5, 2]), array([5, 1]), array([4, 1]), array([4, 2]), array([3, 2]), array([2, 2]), array([2, 3]), array([3, 3]), array([3, 4]), array([2, 4]), array([3, 4]), array([4, 4]), array([5, 4]), array([4, 4]), array([5, 4]), array([5, 3]), array([5, 2]), array([5, 2]), array([4, 2]), array([3, 2]), array([3, 1]), array([2, 1]), array([2, 2]), array([3, 2]), array([3, 3]), array([3, 4]), array([4, 4]), array([4, 3]), array([4, 4]), array([4, 5]), array([3, 5])]\n",
      "Goal: [4 3]\n",
      "Episode: 5/250, steps: 14, e: 0.98\n",
      "State list: [array([1, 2]), array([1, 1]), array([2, 1]), array([2, 2]), array([2, 1]), array([2, 2]), array([2, 3]), array([2, 2]), array([3, 2]), array([3, 1]), array([2, 1]), array([2, 2]), array([2, 3]), array([2, 4])]\n",
      "Goal: [3 1]\n",
      "Episode: 6/250, steps: 3, e: 0.98\n",
      "State list: [array([2, 4]), array([3, 4]), array([3, 3])]\n",
      "Episode: 7/250, steps: 100, e: 0.97\n",
      "State list: [array([1, 5]), array([2, 5]), array([1, 5]), array([1, 4]), array([2, 4]), array([1, 4]), array([1, 3]), array([2, 3]), array([2, 2]), array([2, 3]), array([2, 2]), array([2, 1]), array([2, 0]), array([1, 0]), array([0, 0]), array([0, 0]), array([0, 0]), array([0, 0]), array([0, 0]), array([0, 1]), array([1, 1]), array([0, 1]), array([0, 1]), array([0, 2]), array([1, 2]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 2]), array([0, 2]), array([1, 2]), array([0, 2]), array([1, 2]), array([1, 3]), array([1, 4]), array([1, 5]), array([1, 5]), array([0, 5]), array([0, 5]), array([0, 5]), array([1, 5]), array([1, 4]), array([1, 3]), array([1, 4]), array([2, 4]), array([2, 5]), array([2, 5]), array([2, 4]), array([2, 3]), array([2, 4]), array([1, 4]), array([0, 4]), array([0, 3]), array([0, 3]), array([1, 3]), array([2, 3]), array([1, 3]), array([0, 3]), array([0, 4]), array([0, 4]), array([0, 4]), array([1, 4]), array([0, 4]), array([0, 5]), array([1, 5]), array([2, 5]), array([2, 5]), array([1, 5]), array([2, 5]), array([3, 5]), array([3, 5]), array([3, 5]), array([3, 5]), array([3, 5]), array([3, 4]), array([2, 4]), array([1, 4]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 3]), array([1, 3]), array([2, 3]), array([2, 4]), array([3, 4]), array([3, 5]), array([2, 5]), array([3, 5]), array([2, 5]), array([2, 5]), array([1, 5]), array([0, 5]), array([0, 5]), array([0, 5]), array([0, 5]), array([1, 5]), array([0, 5]), array([0, 5]), array([0, 5])]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(agent\u001b[39m.\u001b[39mmemory) \u001b[39m>\u001b[39m agent\u001b[39m.\u001b[39mbatch_size:\n\u001b[0;32m---> 32\u001b[0m     agent\u001b[39m.\u001b[39;49mreplay()\n\u001b[1;32m     33\u001b[0m \u001b[39mif\u001b[39;00m agent\u001b[39m.\u001b[39mepsilon \u001b[39m>\u001b[39m agent\u001b[39m.\u001b[39mepsilon_min:\n\u001b[1;32m     34\u001b[0m     agent\u001b[39m.\u001b[39mepsilon \u001b[39m=\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m agent\u001b[39m.\u001b[39mepsilon_min) \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mexp(\u001b[39m-\u001b[39magent\u001b[39m.\u001b[39mepsilon_decay\u001b[39m*\u001b[39mepisode) \u001b[39m+\u001b[39m agent\u001b[39m.\u001b[39mepsilon_min\n",
      "Cell \u001b[0;32mIn[7], line 46\u001b[0m, in \u001b[0;36mAgent.replay\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     43\u001b[0m     input_next \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconvert_to_tensor(input_next)\n\u001b[1;32m     44\u001b[0m     input_next \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mexpand_dims(input_next, \u001b[39m0\u001b[39m)\n\u001b[0;32m---> 46\u001b[0m     target \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgamma \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mamax(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_model\u001b[39m.\u001b[39;49mpredict(input_next, verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)[\u001b[39m0\u001b[39m])\n\u001b[1;32m     48\u001b[0m \u001b[39m# Pre-process the current state input\u001b[39;00m\n\u001b[1;32m     49\u001b[0m inputt \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate((state, goal))\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py:2349\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2340\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[1;32m   2341\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   2342\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUsing Model.predict with MultiWorkerMirroredStrategy \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2343\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mor TPUStrategy and AutoShardPolicy.FILE might lead to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2346\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m   2347\u001b[0m         )\n\u001b[0;32m-> 2349\u001b[0m data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39;49mget_data_handler(\n\u001b[1;32m   2350\u001b[0m     x\u001b[39m=\u001b[39;49mx,\n\u001b[1;32m   2351\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m   2352\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps,\n\u001b[1;32m   2353\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m   2354\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m   2355\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   2356\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   2357\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   2358\u001b[0m     model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   2359\u001b[0m     steps_per_execution\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_steps_per_execution,\n\u001b[1;32m   2360\u001b[0m )\n\u001b[1;32m   2362\u001b[0m \u001b[39m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[1;32m   2363\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(callbacks, callbacks_module\u001b[39m.\u001b[39mCallbackList):\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/data_adapter.py:1583\u001b[0m, in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1581\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(kwargs[\u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39m_cluster_coordinator\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1582\u001b[0m     \u001b[39mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m-> 1583\u001b[0m \u001b[39mreturn\u001b[39;00m DataHandler(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/data_adapter.py:1260\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1257\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution \u001b[39m=\u001b[39m steps_per_execution\n\u001b[1;32m   1259\u001b[0m adapter_cls \u001b[39m=\u001b[39m select_data_adapter(x, y)\n\u001b[0;32m-> 1260\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_adapter \u001b[39m=\u001b[39m adapter_cls(\n\u001b[1;32m   1261\u001b[0m     x,\n\u001b[1;32m   1262\u001b[0m     y,\n\u001b[1;32m   1263\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m   1264\u001b[0m     steps\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[1;32m   1265\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs \u001b[39m-\u001b[39;49m initial_epoch,\n\u001b[1;32m   1266\u001b[0m     sample_weights\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1267\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[1;32m   1268\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   1269\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   1270\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   1271\u001b[0m     distribution_strategy\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49mdistribute\u001b[39m.\u001b[39;49mget_strategy(),\n\u001b[1;32m   1272\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m   1273\u001b[0m )\n\u001b[1;32m   1275\u001b[0m strategy \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39mget_strategy()\n\u001b[1;32m   1277\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_step \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/data_adapter.py:307\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[39mreturn\u001b[39;00m indices\n\u001b[1;32m    302\u001b[0m \u001b[39m# We prefetch a single element. Computing large permutations can take\u001b[39;00m\n\u001b[1;32m    303\u001b[0m \u001b[39m# quite a while so we don't want to wait for prefetching over an epoch\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[39m# boundary to trigger the next permutation. On the other hand, too many\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[39m# simultaneous shuffles can contend on a hardware level and degrade all\u001b[39;00m\n\u001b[1;32m    306\u001b[0m \u001b[39m# performance.\u001b[39;00m\n\u001b[0;32m--> 307\u001b[0m indices_dataset \u001b[39m=\u001b[39m indices_dataset\u001b[39m.\u001b[39;49mmap(permutation)\u001b[39m.\u001b[39mprefetch(\u001b[39m1\u001b[39m)\n\u001b[1;32m    309\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mslice_batch_indices\u001b[39m(indices):\n\u001b[1;32m    310\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Convert a Tensor of indices into a dataset of batched indices.\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \n\u001b[1;32m    312\u001b[0m \u001b[39m    This step can be accomplished in several ways. The most natural is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[39m      A Dataset of batched indices.\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:2240\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2236\u001b[0m \u001b[39m# Loaded lazily due to a circular dependency (dataset_ops -> map_op ->\u001b[39;00m\n\u001b[1;32m   2237\u001b[0m \u001b[39m# dataset_ops).\u001b[39;00m\n\u001b[1;32m   2238\u001b[0m \u001b[39m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[1;32m   2239\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m map_op\n\u001b[0;32m-> 2240\u001b[0m \u001b[39mreturn\u001b[39;00m map_op\u001b[39m.\u001b[39;49m_map_v2(\n\u001b[1;32m   2241\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   2242\u001b[0m     map_func,\n\u001b[1;32m   2243\u001b[0m     num_parallel_calls\u001b[39m=\u001b[39;49mnum_parallel_calls,\n\u001b[1;32m   2244\u001b[0m     deterministic\u001b[39m=\u001b[39;49mdeterministic,\n\u001b[1;32m   2245\u001b[0m     name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/data/ops/map_op.py:37\u001b[0m, in \u001b[0;36m_map_v2\u001b[0;34m(input_dataset, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[39mif\u001b[39;00m deterministic \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m debug_mode\u001b[39m.\u001b[39mDEBUG_MODE:\n\u001b[1;32m     35\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mThe `deterministic` argument has no effect unless the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     36\u001b[0m                   \u001b[39m\"\u001b[39m\u001b[39m`num_parallel_calls` argument is specified.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m   \u001b[39mreturn\u001b[39;00m _MapDataset(\n\u001b[1;32m     38\u001b[0m       input_dataset, map_func, preserve_cardinality\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, name\u001b[39m=\u001b[39;49mname)\n\u001b[1;32m     39\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     40\u001b[0m   \u001b[39mreturn\u001b[39;00m _ParallelMapDataset(\n\u001b[1;32m     41\u001b[0m       input_dataset,\n\u001b[1;32m     42\u001b[0m       map_func,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m       preserve_cardinality\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     46\u001b[0m       name\u001b[39m=\u001b[39mname)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/data/ops/map_op.py:107\u001b[0m, in \u001b[0;36m_MapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_use_inter_op_parallelism \u001b[39m=\u001b[39m use_inter_op_parallelism\n\u001b[1;32m    106\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_preserve_cardinality \u001b[39m=\u001b[39m preserve_cardinality\n\u001b[0;32m--> 107\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func \u001b[39m=\u001b[39m structured_function\u001b[39m.\u001b[39;49mStructuredFunctionWrapper(\n\u001b[1;32m    108\u001b[0m     map_func,\n\u001b[1;32m    109\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transformation_name(),\n\u001b[1;32m    110\u001b[0m     dataset\u001b[39m=\u001b[39;49minput_dataset,\n\u001b[1;32m    111\u001b[0m     use_legacy_function\u001b[39m=\u001b[39;49muse_legacy_function)\n\u001b[1;32m    112\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name \u001b[39m=\u001b[39m name\n\u001b[1;32m    113\u001b[0m variant_tensor \u001b[39m=\u001b[39m gen_dataset_ops\u001b[39m.\u001b[39mmap_dataset(\n\u001b[1;32m    114\u001b[0m     input_dataset\u001b[39m.\u001b[39m_variant_tensor,  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func\u001b[39m.\u001b[39mfunction\u001b[39m.\u001b[39mcaptured_inputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    118\u001b[0m     preserve_cardinality\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_preserve_cardinality,\n\u001b[1;32m    119\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_common_args)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/data/ops/structured_function.py:261\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m       warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    255\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    256\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    257\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    258\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    259\u001b[0m     fn_factory \u001b[39m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[0;32m--> 261\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function \u001b[39m=\u001b[39m fn_factory()\n\u001b[1;32m    262\u001b[0m \u001b[39m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[1;32m    263\u001b[0m add_to_graph \u001b[39m&\u001b[39m\u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:232\u001b[0m, in \u001b[0;36mTracingCompiler.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_concrete_function\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    224\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \n\u001b[1;32m    226\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[39m      `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m   concrete_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_concrete_function_garbage_collected(\n\u001b[1;32m    233\u001b[0m       \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    234\u001b[0m   concrete_function\u001b[39m.\u001b[39m_garbage_collector\u001b[39m.\u001b[39mrelease()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    235\u001b[0m   \u001b[39mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:202\u001b[0m, in \u001b[0;36mTracingCompiler._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_spec\u001b[39m.\u001b[39mmake_canonicalized_monomorphic_type(args, kwargs)\n\u001b[1;32m    201\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m--> 202\u001b[0m   concrete_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_concrete_function(args, kwargs)\n\u001b[1;32m    203\u001b[0m   seen_names \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[1;32m    204\u001b[0m   concrete_function\u001b[39m.\u001b[39m_arg_keywords \u001b[39m=\u001b[39m []  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:166\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_concrete_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m   args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_signature\n\u001b[1;32m    164\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> 166\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:396\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m   args \u001b[39m=\u001b[39m placeholder_bound_args\u001b[39m.\u001b[39margs\n\u001b[1;32m    394\u001b[0m kwargs \u001b[39m=\u001b[39m placeholder_bound_args\u001b[39m.\u001b[39mkwargs\n\u001b[0;32m--> 396\u001b[0m concrete_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_concrete_function(\n\u001b[1;32m    397\u001b[0m     args, kwargs, func_graph)\n\u001b[1;32m    399\u001b[0m \u001b[39m# TODO(b/263520817): Remove access to private attribute.\u001b[39;00m\n\u001b[1;32m    400\u001b[0m graph_capture_container \u001b[39m=\u001b[39m concrete_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39m_function_captures  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:299\u001b[0m, in \u001b[0;36mTracingCompiler._create_concrete_function\u001b[0;34m(self, args, kwargs, func_graph)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    297\u001b[0m   arg_names \u001b[39m=\u001b[39m base_arg_names\n\u001b[0;32m--> 299\u001b[0m concrete_function \u001b[39m=\u001b[39m monomorphic_function\u001b[39m.\u001b[39;49mConcreteFunction(\n\u001b[1;32m    300\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[1;32m    301\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[1;32m    302\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[1;32m    303\u001b[0m         args,\n\u001b[1;32m    304\u001b[0m         kwargs,\n\u001b[1;32m    305\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    306\u001b[0m         func_graph\u001b[39m=\u001b[39;49mfunc_graph,\n\u001b[1;32m    307\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[1;32m    308\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[1;32m    309\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[1;32m    310\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value,\n\u001b[1;32m    311\u001b[0m         create_placeholders\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m    312\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_function_attributes,\n\u001b[1;32m    313\u001b[0m     spec\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_spec,\n\u001b[1;32m    314\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;49;00m\n\u001b[1;32m    315\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;49;00m\n\u001b[1;32m    316\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;49;00m\n\u001b[1;32m    317\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;49;00m\n\u001b[1;32m    318\u001b[0m     shared_func_graph\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    319\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction.__init__\u001b[0;34m(self, func_graph, attrs, shared_func_graph, spec)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_captured_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func_graph\u001b[39m.\u001b[39mexternal_captures \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func_graph\u001b[39m.\u001b[39mdeferred_external_captures\n\u001b[1;32m   1321\u001b[0m \u001b[39m# spec defines the structured signature.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_function_spec(spec)\n\u001b[1;32m   1324\u001b[0m \u001b[39mif\u001b[39;00m attrs \u001b[39mand\u001b[39;00m attributes_lib\u001b[39m.\u001b[39mIMPLEMENTS \u001b[39min\u001b[39;00m attrs:\n\u001b[1;32m   1325\u001b[0m   \u001b[39m# The alternative is to silently drop \"implements\" tag\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m   \u001b[39m# but it seems likely it would lead to hard to catch bugs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1331\u001b[0m   \u001b[39m# Anytime we annotate existing function we probably want to wrap\u001b[39;00m\n\u001b[1;32m   1332\u001b[0m   \u001b[39m# it with safe read_value for backward compatibility.\u001b[39;00m\n\u001b[1;32m   1333\u001b[0m   has_resource_vars \u001b[39m=\u001b[39m \u001b[39many\u001b[39m(\n\u001b[1;32m   1334\u001b[0m       inp\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m dtypes\u001b[39m.\u001b[39mresource \u001b[39mfor\u001b[39;00m inp \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1374\u001b[0m, in \u001b[0;36mConcreteFunction._set_function_spec\u001b[0;34m(self, spec)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_spec \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1373\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pre_initialized_function_spec \u001b[39m=\u001b[39m spec\n\u001b[0;32m-> 1374\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initialize_function_spec()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1405\u001b[0m, in \u001b[0;36mConcreteFunction._initialize_function_spec\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1394\u001b[0m vararg_indices \u001b[39m=\u001b[39m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(spec\u001b[39m.\u001b[39marg_names), \u001b[39mlen\u001b[39m(arg_specs))\n\u001b[1;32m   1395\u001b[0m fullargspec \u001b[39m=\u001b[39m tf_inspect\u001b[39m.\u001b[39mFullArgSpec(\n\u001b[1;32m   1396\u001b[0m     args\u001b[39m=\u001b[39m\u001b[39mlist\u001b[39m(args) \u001b[39m+\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39marg\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m vararg_indices],\n\u001b[1;32m   1397\u001b[0m     varargs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1402\u001b[0m         (k, function_spec\u001b[39m.\u001b[39mBOUND_VALUE) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m kwarg_specs),\n\u001b[1;32m   1403\u001b[0m     annotations\u001b[39m=\u001b[39mspec\u001b[39m.\u001b[39mfullargspec\u001b[39m.\u001b[39mannotations)\n\u001b[1;32m   1404\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_spec \u001b[39m=\u001b[39m (\n\u001b[0;32m-> 1405\u001b[0m     function_spec\u001b[39m.\u001b[39;49mFunctionSpec\u001b[39m.\u001b[39;49mfrom_fullargspec_and_signature(\n\u001b[1;32m   1406\u001b[0m         fullargspec,\n\u001b[1;32m   1407\u001b[0m         spec\u001b[39m.\u001b[39;49mis_method,\n\u001b[1;32m   1408\u001b[0m         spec\u001b[39m.\u001b[39;49minput_signature,\n\u001b[1;32m   1409\u001b[0m         spec\u001b[39m.\u001b[39;49mis_pure,\n\u001b[1;32m   1410\u001b[0m         name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func_graph\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m   1411\u001b[0m     )\n\u001b[1;32m   1412\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/function_spec.py:241\u001b[0m, in \u001b[0;36mFunctionSpec.from_fullargspec_and_signature\u001b[0;34m(cls, fullargspec, is_bound_method, input_signature, is_pure, name, jit_compile)\u001b[0m\n\u001b[1;32m    239\u001b[0m   input_signature \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(input_signature)\n\u001b[1;32m    240\u001b[0m   _validate_signature(input_signature)\n\u001b[0;32m--> 241\u001b[0m   function_type \u001b[39m=\u001b[39m function_type_lib\u001b[39m.\u001b[39;49madd_type_constraints(\n\u001b[1;32m    242\u001b[0m       function_type, input_signature, default_values)\n\u001b[1;32m    244\u001b[0m \u001b[39mreturn\u001b[39;00m FunctionSpec(function_type, default_values, is_bound_method, is_pure,\n\u001b[1;32m    245\u001b[0m                     name, jit_compile)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/core/function/polymorphism/function_type.py:456\u001b[0m, in \u001b[0;36madd_type_constraints\u001b[0;34m(function_type, input_signature, default_values)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[39mif\u001b[39;00m param\u001b[39m.\u001b[39mname \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    453\u001b[0m   \u001b[39m# Type constraints do not apply on them.\u001b[39;00m\n\u001b[1;32m    454\u001b[0m   parameters\u001b[39m.\u001b[39mappend(Parameter(\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m, sanitized_kind, param\u001b[39m.\u001b[39moptional, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m--> 456\u001b[0m \u001b[39melif\u001b[39;00m param\u001b[39m.\u001b[39mkind \u001b[39mis\u001b[39;00m param\u001b[39m.\u001b[39;49mVAR_KEYWORD:\n\u001b[1;32m    457\u001b[0m   \u001b[39m# Disabled when input_signature is specified.\u001b[39;00m\n\u001b[1;32m    458\u001b[0m   \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    460\u001b[0m \u001b[39melif\u001b[39;00m param\u001b[39m.\u001b[39mkind \u001b[39mis\u001b[39;00m param\u001b[39m.\u001b[39mVAR_POSITIONAL:\n\u001b[1;32m    461\u001b[0m   \u001b[39m# Convert into Positional Only args based on length of constraints.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the agent\n",
    "\n",
    "num_episodes = 250\n",
    "# num_episodes = 5\n",
    "reward_lst = []\n",
    "\n",
    "file = open('rewards.txt', 'a')\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    state_lst = [] # DEBUG\n",
    "    ep_reward = 0 # DEBUG\n",
    "    state = agent.env.reset()\n",
    "    for step in range(agent.env.max_steps):\n",
    "        state_lst.append(state.copy()) # DEBUG\n",
    "        # print('State:', state) # DEBUG\n",
    "        # print('state_lst:', state_lst) # DEBUG\n",
    "        action = agent.act(state)\n",
    "        # print('Action:', action) # DEBUG\n",
    "        next_state, reward, done = agent.env.step(action)\n",
    "        ep_reward += reward # DEBUG\n",
    "        # print(f\"next_state: {next_state}, reward: {reward}, done: {done}\") # DEBUG\n",
    "        # next_state = np.reshape(next_state, [1, 2])\n",
    "        agent.add_to_memory(state, agent.env.goal, action, reward, next_state, done)\n",
    "        state = next_state\n",
    "        if done:\n",
    "            if np.array_equal(agent.env.goal, agent.env.pos): # Reached the goal\n",
    "                agent.env.reset_goal()\n",
    "            print('Episode: {}/{}, steps: {}, e: {:.2}'.format(episode, num_episodes, step+1, agent.epsilon))\n",
    "            print('State list:', state_lst) # DEBUG\n",
    "            break\n",
    "    if len(agent.memory) > agent.batch_size:\n",
    "        agent.replay()\n",
    "    if agent.epsilon > agent.epsilon_min:\n",
    "        agent.epsilon = (1 - agent.epsilon_min) * np.exp(-agent.epsilon_decay*episode) + agent.epsilon_min\n",
    "    if episode % 5 == 0:\n",
    "        agent.model.save('doublenet_dqn_diff_start_diff_goal.h5')    \n",
    "    agent.target_model.set_weights(agent.model.get_weights())\n",
    "\n",
    "    reward_lst.append(ep_reward) # DEBUG\n",
    "    file.write(f\"{episode},{ep_reward}\\n\") # DEBUG\n",
    "    file.flush() # DEBUG\n",
    "    \n",
    "print('Average reward:', np.mean(reward_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the agent\n",
    "\n",
    "state = agent.env.reset()\n",
    "goal = agent.env.reset_goal()\n",
    "print('Goal:', goal)\n",
    "for step in range(agent.env.max_steps):\n",
    "    print('State:', state)\n",
    "    inputt = np.concatenate((state, goal))\n",
    "    inputt = tf.convert_to_tensor(inputt)\n",
    "    inputt = tf.expand_dims(inputt, 0)\n",
    "    action = agent.predict(inputt)\n",
    "    next_state, reward, done = agent.env.step(action)\n",
    "    state = next_state\n",
    "    if done:\n",
    "        print('Steps: ', step+1)\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(reward_lst)\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Reward\")\n",
    "# PLot mean line for 10 episodes\n",
    "mean_lst = []\n",
    "for i in range(len(reward_lst)):\n",
    "    if i < 10:\n",
    "        mean_lst.append(np.mean(reward_lst[:i+1]))\n",
    "    else:\n",
    "        mean_lst.append(np.mean(reward_lst[i-10:i+1]))\n",
    "plt.plot(mean_lst)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.model.save('doublenet_dqn_diff_start_diff_goal.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
